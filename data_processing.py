# -*- coding: utf-8 -*-
"""
Module de traitement de donnÃ©es et d'analyse de sentiment
Utilise la configuration centralisÃ©e et gÃ¨re les dÃ©pendances optionnelles
"""

import re
import string
from config.settings import TextProcessingConfig

# Gestion des imports optionnels
nltk_available = False
try:
    import nltk
    from nltk.corpus import stopwords
    nltk_available = True
    print("ğŸ“š NLTK disponible")
except ImportError:
    print("ğŸ“š NLTK non disponible, utilisation des stopwords basiques")

def initialize_nltk():
    """Initialise NLTK avec gestion d'erreur"""
    global stopwords_fr
    
    if not nltk_available:
        stopwords_fr = TextProcessingConfig.BASIC_FRENCH_STOPWORDS
        return
    
    try:
        # TÃ©lÃ©charger stopwords de maniÃ¨re silencieuse
        nltk.download('stopwords', quiet=True)
        stopwords_fr = set(stopwords.words("french"))
        print("âœ… Stopwords franÃ§ais chargÃ©s depuis NLTK")
    except Exception as e:
        print(f"âš ï¸ Erreur NLTK: {e}")
        stopwords_fr = TextProcessingConfig.BASIC_FRENCH_STOPWORDS
        print("âœ… Stopwords basiques utilisÃ©s")

def clean_text(text: str) -> str:
    """
    Nettoie et normalise le texte d'entrÃ©e
    
    Args:
        text: Le texte brut Ã  nettoyer
        
    Returns:
        Le texte nettoyÃ© et normalisÃ©
    """
    if not text or not isinstance(text, str):
        return ""
    
    # Conversion en minuscules
    text = text.lower().strip()
    
    # Suppression des URLs
    text = re.sub(r"http\S+|www\S+|https\S+", "", text, flags=re.MULTILINE)
    
    # Suppression des emojis avec regex Unicode
    emoji_pattern = re.compile(
        "["
        u"\U0001F600-\U0001F64F"  # emoticons
        u"\U0001F300-\U0001F5FF"  # symboles & pictographes
        u"\U0001F680-\U0001F6FF"  # transport & map
        u"\U0001F1E0-\U0001F1FF"  # flags
        u"\U00002700-\U000027BF"  # dingbats
        u"\U0001f926-\U0001f937"
        u"\U00010000-\U0010ffff"
        u"\u2640-\u2642" 
        u"\u2600-\u2B55"
        u"\u200d"
        u"\u23cf"
        u"\u23e9"
        u"\u231a"
        u"\ufe0f"  # diacritiques
        u"\u3030"
        "]+", 
        flags=re.UNICODE
    )
    text = emoji_pattern.sub('', text)
    
    # Suppression de la ponctuation
    text = text.translate(str.maketrans("", "", string.punctuation))
    
    # Conservation des caractÃ¨res franÃ§ais et chiffres
    text = re.sub(r"[^a-zÃ Ã¢Ã¤Ã©Ã¨ÃªÃ«Ã®Ã¯Ã´Ã¶Ã¹Ã»Ã¼Ã§0-9\s]", " ", text)
    
    # Suppression des stopwords
    if stopwords_fr:
        words = text.split()
        text = " ".join([word for word in words if word not in stopwords_fr and len(word) > 2])
    
    # Nettoyage final des espaces
    text = re.sub(r"\s+", " ", text).strip()
    
    return text

def analyze_sentiment_simple(text: str) -> str:
    """
    Analyse simple du sentiment basÃ©e sur des mots-clÃ©s
    
    Args:
        text: Le texte Ã  analyser
        
    Returns:
        Le sentiment dÃ©tectÃ© ("positive", "negative", "neutral")
    """
    if not text:
        return "neutral"
    
    text_lower = text.lower()
    
    # Mots-clÃ©s positifs
    positive_keywords = {
        'excellent', 'fantastique', 'parfait', 'super', 'gÃ©nial', 'formidable',
        'merveilleux', 'incroyable', 'magnifique', 'extraordinaire', 'remarquable',
        'satisfait', 'content', 'heureux', 'ravi', 'enchantÃ©', 'impressionnÃ©',
        'recommande', 'qualitÃ©', 'rapide', 'efficace', 'professionnel', 'top',
        'bon', 'bien', 'mieux', 'meilleur', 'love', 'adore', 'parfait'
    }
    
    # Mots-clÃ©s nÃ©gatifs
    negative_keywords = {
        'mauvais', 'terrible', 'horrible', 'nul', 'catastrophique', 'dÃ©cevant',
        'insatisfait', 'mÃ©content', 'frustrÃ©', 'Ã©nervÃ©', 'fÃ¢chÃ©', 'dÃ©Ã§u',
        'problÃ¨me', 'erreur', 'dÃ©faut', 'cassÃ©', 'abÃ®mÃ©', 'retard', 'lent',
        'cher', 'arnaque', 'vol', 'scandale', 'inadmissible', 'inacceptable',
        'pire', 'dÃ©teste', 'horreur', 'cauchemar', 'regret'
    }
    
    # Compter les occurrences
    positive_count = sum(1 for word in positive_keywords if word in text_lower)
    negative_count = sum(1 for word in negative_keywords if word in text_lower)
    
    # DÃ©terminer le sentiment
    if positive_count > negative_count and positive_count > 0:
        return "positive"
    elif negative_count > positive_count and negative_count > 0:
        return "negative"
    else:
        return "neutral"

def label_sentiment(numeric_label: int) -> str:
    """
    Convertit un label numÃ©rique en sentiment textuel
    BasÃ© sur l'Ã©chelle Amazon (1-5 Ã©toiles)
    
    Args:
        numeric_label: Score numÃ©rique (gÃ©nÃ©ralement 1-5)
        
    Returns:
        Le sentiment correspondant ("positive", "negative", "neutral")
    """
    thresholds = TextProcessingConfig.SENTIMENT_THRESHOLDS
    
    if numeric_label >= thresholds["positive"]:
        return "positive"
    elif numeric_label < thresholds["negative"]:
        return "negative"
    else:
        return "neutral"

def process_review(text: str, numeric_rating: int = None) -> dict:
    """
    Traite complÃ¨tement un avis client
    
    Args:
        text: Le texte de l'avis
        numeric_rating: Note numÃ©rique optionnelle
        
    Returns:
        Dictionnaire avec le texte nettoyÃ© et le sentiment
    """
    # Nettoyer le texte
    cleaned_text = clean_text(text)
    
    # Analyser le sentiment
    if numeric_rating is not None:
        # Utiliser la note numÃ©rique si disponible
        sentiment = label_sentiment(numeric_rating)
    else:
        # Analyser le texte si pas de note
        sentiment = analyze_sentiment_simple(cleaned_text)
    
    return {
        "original_text": text,
        "cleaned_text": cleaned_text,
        "sentiment": sentiment,
        "numeric_rating": numeric_rating
    }

def load_reviews_dataset(limit: int = 1000) -> list:
    """
    Charge un dataset d'avis (fonction optionnelle)
    
    Args:
        limit: Nombre maximum d'avis Ã  charger
        
    Returns:
        Liste de dictionnaires avec les avis traitÃ©s
    """
    try:
        import pandas as pd
        from datasets import load_dataset
        
        print(f"ğŸ“¥ Chargement du dataset (limite: {limit})")
        dataset = load_dataset(
            "SetFit/amazon_reviews_multi_fr",
            split=f"train[:{limit}]"
        )
        
        reviews = []
        for item in dataset:
            processed = process_review(item['text'], item['label'])
            reviews.append(processed)
        
        print(f"âœ… {len(reviews)} avis chargÃ©s et traitÃ©s")
        return reviews
        
    except ImportError as e:
        print(f"ğŸ“¦ Modules de dataset non disponibles: {e}")
        return []
    except Exception as e:
        print(f"âŒ Erreur chargement dataset: {e}")
        return []

# Initialisation du module
print("ğŸ”§ Initialisation du module de traitement de donnÃ©es...")
initialize_nltk()
print("âœ… Module de traitement prÃªt")

# Tests si exÃ©cutÃ© directement
if __name__ == "__main__":
    print("\nğŸ§ª Test du traitement de donnÃ©es...")
    
    tests = [
        ("Produit FANTASTIQUE! ğŸ˜Š http://test.com J'adore vraiment!", None),
        ("Service trÃ¨s dÃ©cevant, problÃ¨me majeur...", None),
        ("Correct sans plus, peut mieux faire", None),
        ("Avis avec note", 5),
        ("Avis nÃ©gatif avec note", 1)
    ]
    
    for text, rating in tests:
        result = process_review(text, rating)
        print(f"\nğŸ“ Original: {text}")
        print(f"ğŸ§¹ NettoyÃ©: {result['cleaned_text']}")
        print(f"ğŸ˜Š Sentiment: {result['sentiment']}")
        if rating:
            print(f"â­ Note: {rating}")